\chapter{Propagating the Epistemic Uncertainty of the Cost Volume to the DSM}\label{chap:epistemic_uncertainty}
\todoroman{Citer la publication d'origine pour les figure (license IEEE ``Copyright 2024 IEEE. Published in the 2024 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2024), scheduled for 7 - 12 July, 2024 in Athens, Greece. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE. Contact: Manager, Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O. Box 1331 / Piscataway, NJ 08855-1331, USA. Telephone: + Intl. 908-562-3966.'')}

The previous chapter explored the propagation of uncertainty in a stereo matching problem, using a simple cost function, the $\SAD$ and possibility distributions. However, real cases of stereo matching usually do not use a simple cost function such as the SAD, and usually use more advanced and complex cost functions \cite{zabih_non-parametric_1994,zbontar_stereo_2016,laga_survey_2022}). The complexity of the uncertainty propagation as in \Cref{chap:propagating} depends on the cost function used. For instance, the CENSUS cost function \cite{zabih_non-parametric_1994} is designed to be robust to small variations of intensities, while learning-based cost functions can sometimes be very sensitive to noise \cite{szegedy_intriguing_2013,carlini_towards_2017}. The study of the sensitivity to perturbations of learned models is a complex area of research on its own, known as adversarial attacks \cite{chen_shapeshifter_2018, zhao_seeing_2019}. Propagating the uncertainty for advanced cost functions as in \Cref{chap:propagating} is a complex task, even more when considering Semi Global Matching or similar regularization steps using recursive operations. It has lead to different approaches for quantifying uncertainty \cite{hu_quantitative_2012}, and with specialized method learned-based approaches \cite{laga_survey_2022,poggi_confidence_2021,wang_uncertainty_2022}. These methods usually estimate the confidence (or similarly uncertainty) from the output cost volume properties (deep learning based methods can also consider additional sources of information such as input images, disparity map \etc). Adopting such an approach circumvents the complex problem of uncertainty propagation, and can also address the problem of the cost function's interpretation briefly addressed in \Cref{sec:sources_of_uncertainty}, \ie the ability of a cost function's minimum to correspond to the correct disparity. In this chapter, we will study how possibility distributions can be simply used on a cost volume to estimate its epistemic uncertainty. We design a method for traditional 3D reconstruction pipelines, with the final objective of reconstructing 3D models from satellite imagery. The uncertainty is represented by disparity confidence intervals, which complement classical confidence estimations as it provides information on \textit{where} the correct disparity should be. We then propagate disparity confidence intervals in the rest of the stereo pipeline to obtain height confidence intervals, and evaluate their performances.

\section{Cost Functions as Expert Opinions}
In this chapter, we will consider two cost functions:
\begin{enumerate}
    \item CENSUS \cite{zabih_non-parametric_1994}, designed to be robust to radiometric variations preserving the relative orders on intensities
    \item MCCNN \cite{zbontar_stereo_2016}, learned-based similarity measure on a fixed $11\times 11$ window
\end{enumerate}
The CENSUS cost function is a common cost function for cost-volume-based methods, and is used in most 3D pipelines \cite{franchis_automatic_2014,shean_automated_2016,rupnik_micmac_2017,youssefi_cars_2020}. The MCCNN function has been shown to outperform CENSUS on benchmark datasets \cite{zbontar_stereo_2016} and present good generalization properties. Those functions are the two main methods used in the CARS pipeline, for which we will thus attempt to estimate the uncertainty. 

As stated previously, a cost function measures the similarity between patches of two images \(I_L,~I_R\). The similarity for every considered disparity and for every pixels of the left image are then stored in the cost volume, which is itself regularized using SGM algorithm or one of its variants. As such, the cost volume (and by extension all of its cost curves) contains both information on the similarity of patches, but also the global structure of the scene now that continuity constraints on the disparity map have been imposed. For instance, a low value of the cost volume at \( (row, col, d) \) usually indicates that the patches \(I_L(row,col)\)  and \(I_R(row,col+d)\) are somehow similar, and that neighbouring patches with close disparities are also similar. However, those two notions are mixed inside a cost value, so it is hard to differentiate between the similarity and the regularization part. The uncertainty linked to the cost volume is of epistemic nature, due to the regularization (and to the learned nature of the cost function in the case of MCCNN). We thus suggest to consider a cost function similarly as an expert providing insights on how \textit{possible} a match is, opinion for which the uncertainty can be modeled using possibility distributions for instance. We presented possibility distribution in \Cref{sec:possibilities}, which have been used to model the uncertainty of experts opinions in the applications such as groundwater contamination \cite{bardossy_l-_1995, baudrit_joint_2007}. Utilizing possibility distributions leverages the advanced capabilities of imprecise probability (IP) theory for epistemic uncertainty estimation.

Possibility distributions are effective for modeling expert opinions on the uncertainty of imprecise observations, as seen in applications like groundwater contamination \cite{bardossy_l-_1995, baudrit_joint_2007}. In stereo matching, a regularized cost curve obtained using SGM can be likened to an expert's assessment of whether two patches are homologous, based on their features and the overall properties of the cost volume. Utilizing possibility distributions leverages the advanced capabilities of imprecise probability (IP) theory for robust uncertainty estimation.

Stereo matching algorithms attempt to determine the disparity for every pixel of the left image. To do so, we look at the minimal disparity of every cost function separately, instead of considering the whole cost volume. We use the same approach and propose to generate a possibility distribution for each cost curve. To compute those possibility distributions, we first normalize the cost curve into a range of \([0,1]\), using the minimum and maximum values of the global cost volume after regularization. For a pixel \( p = (row,~col) \), the normalized cost curve is given by:
\begin{equation}
    f_{row,~col}^{norm}(d) = \frac{C_V(row,~col,d) - \max C_V}{\min C_V - \max C_V} \label{eq:norm_cost_func}
\end{equation}
Here, the \(\min\) and \(\max\) operations are reversed to ensure higher possibility for lower values of the cost function. To ensure that there always exists a disparity for which the possibility is $1$ (\cref{eq:possibility}), \( f_{row,~col}^{norm} \) is transformed into a possibility distribution \( \pi_{row,~col}(d) \) by adding a constant:
\begin{equation}
    \pi_{row,~col}(d) = f_{row,~col}^{norm}(d) + 1 - \max_{d \in \mathcal{D}} f_{row,~col}^{norm}(d) \label{eq:constant_norm}
\end{equation}
where \(\mathcal{D}\) refers to the disparity range considered. Note that the constants used in \ref{eq:norm_cost_func} are global for all possibility distributions, whereas the constant in \cref{eq:constant_norm} can vary between different possibility distributions. Constants from \cref{eq:norm_cost_func} determine which cost values are said to be the most possible match and impossible matches. Consequently, in order for the constants to be well defined and for the possibility distributions to have similar interpretations between different cost volume, the disparity range and images need to be large enough to ensure that the cost volume contains values for very similar and very dissimilar patches. This hypothesis is usually not very restrictive for the images used in stereo matching problem (except if the whole scene is covered by cloud for instance, which can be detected in advance).

\todoroman{Figure montrant différentes courbes de coût transformées, CENSUS MCCNN}

With the possibility distributions defined, we aim to establish a set of possible disparities that meet a \(90\%\) confidence level. This \( 90\%\) value was chosen following discussions with users and other experts working with the Mic Mac pipeline\comroman{Je pense à Bruno Vallet et Nicolas Champion. Est-ce que je suis trop spécifique en précisant Mic Mac?}. Some users prefer a broader classification such as ``very confident'', ``confident'' and ``not confident''. This type of classification is less specific and could be deduced from the values contained in confidence disparity sets, we thus do not consider them for now.
Possibility distributions represent degrees of possibility, which are different from probabilities (or a \( 90\%\) value in that regard). However, it is possible to define a set of probability distributions given a possibility distribution \( \pi_{row,~col} \), as described in \cref{eq:credal_set_possibility}. We refer to this credal set as \( \M(\pi_{row,~col}) \). We can use this interpretation of a possibility distribution to determine the set of possible disparities: a disparity \( d \) is considered unlikely if its probability, under any distribution \( P \) in \( \M(\pi_{row,~col}) \), is less than \(0.9\). Formally, the set \( D^{row,~col} \) of possible disparities is defined as:
\begin{equation}
    D^{row,~col}=\{ d~|~\exists P\in\M(\pi_{row,~col})~\st~P(\{d\})\geqslant 0.9 \}\label{eq:disparity_possible_set_with_proba}
\end{equation}

This interpretation has the advantage of making explicit use of this \( 90\%\) threshold. However, it does not guarantee that every \( P \) in \( \M(\pi_{row,~col}) \) is superior to \( 90\%\) for confident disparities, only that there exists at least one dominating the \( 90\%\) threshold. This is a rather optimist interpretation of our possibility distribution. A conservative approach could have instead been to consider every set whose necessity is superior to \(0.9\) (and take the union of those sets). This approach leads to vacuous sets of disparities and have very little interest. Note that all those interpretations suppose there exists a set of probability distributions correctly modeled by \( \pi_{row,~col} \) and describing the uncertainty on the disparities. The existence, and meaning, of a probability distribution on the disparities is subject to discussion. 

It is possible to define \( D^{row,~col} \) without supposing that the probabilistic interpretation of \( \M(\pi_{row,~col}) \) has a meaning in our problem. Indeed, it holds that 
\begin{equation}
    D^{row,~col}=\{ d~|~\pi_{row,~col}(d)\geqslant 0.9 \}\label{eq:disparity_possible_set}
\end{equation}
The definitions \eqref{eq:disparity_possible_set_with_proba} and \eqref{eq:disparity_possible_set} are equivalent as:
\begin{align*}
    \{ d~|~\pi_{row,~col}(\{d\})\geqslant 0.9 \} =& \{ d~|~\Pi_{row,~col}(\{d\})\geqslant 0.9 \}\\
\end{align*}
where \( \Pi_{row,~col} \) is the possibility function (or dual function of the necessity) defined by \( \pi_{row,~col} \) as in \cref{eq:bel_pl} .As the bounds of the credal set are reached, then for a given \(d\) there always exists \(P\in\M(\pi_{row,~col})\) such that \( P(\{d\}) = \Pi_{row,~col}(\{d\})\geqslant 0.9\). This leads to the two definition being equivalent.

The set defined in \eqref{eq:disparity_possible_set} is also the \(\alpha\)-cut with \(\alpha=0.9\) of the possibility distribution. 
\begin{equation}
    I_\alpha(row,~col) = [\min C^{\pi_{row,~col}}_\alpha, \max C^{\pi_{row,~col}}_\alpha] \label{eq:confidence_interval}
\end{equation}

While this reduces detailed information from \( C^{\pi_{row,~col}}_\alpha \), it simplifies processing and conserves memory. The confidence level of \( I_\alpha(row,~col) \) is at least as high as \( C^{\pi_{row,~col}}_\alpha \) since \( C^{\pi_{row,~col}}_\alpha \subseteq I_\alpha(row,~col) \). 

%\Cref{fig:possibility} illustrates confidence intervals derived from these distributions.
Disparity at least possible to 0.9 lead to 0.9 confident intervals. 

\section{Computing Disparity Intervals}
Simple seuil mais avec une base théorique

Ambiguity et régularization dans les zones de faibles confiance etc
\section{Propagation in the CARS Pipeline}
Rasterization and small ideas with Gabriela?
Impact of tiling : cost volume min and max is not the same from one tile to another (statistically it should be close, provided that the tile is big enough and the disparity interval is also large enough)

\subsection{Unexplored leads}
Patatoides sur les lignes de visées. Un pixel est représenté par des coordonées précises mais est en fait l'aggrégation d'information radiométriques issues d'une surface au sol. On pourrait donc imaginer que les lignes de visées ne sont pas une ligne mais plus un cône/cylindre (approx), et donc qu'on pourrait donc représenter la position d'un point 3D comme l'intersection de deux volumes (cône + intervalles de disparité).   

\section{Coregistration}
DEM Compare 
\pagebreak
\blankpage