\chapter{Epistemic uncertainty in stereo matching}\label{chap:epistemic_uncertainty}
The previous chapter explored the propagation of uncertainty in a stereo matching problem, using a simple cost function and possibility distributions. However, real cases of stereo matching usually do not use a simple cost function such as the SAD, and usually use more advanced and complex cost functions \cite{zabih_non-parametric_1994,zbontar_stereo_2016,laga_survey_2022}). The complexity of the uncertainty propagation as in chapter \ref{chap:propagating} depends on the cost function used. For instance, the CENSUS cost function \cite{zabih_non-parametric_1994} is designed to be robust to small variations of intensities, while learning-based cost functions can sometimes be very sensitive to noise \cite{szegedy_intriguing_2013,carlini_towards_2017}. The study of the sensitivity to perturbations of learned models is a complex area of research on its own, known as adversarial attacks \cite{chen_shapeshifter_2018, zhao_seeing_2019}. Propagating the uncertainty for advanced cost functions as in chapter \ref{chap:propagating} is a complex task, even more when considering Semi Global Matching or similar regularization steps using recursive operations. It has lead to different approaches for quantifying uncertainty \cite{hu_quantitative_2012}, and with specialized method learned-based approaches \cite{laga_survey_2022,poggi_confidence_2021,wang_uncertainty_2022}. These methods usually estimate the confidence (or similarly uncertainty) from the output cost volume properties (deep learning based methods can also consider additional sources of information such as input images, disparity map \etc). Adopting such an approach circumvents the complex problem of uncertainty propagation, and can also address the problem of the cost function's interpretation briefly addressed in section \ref{sec:sources_of_uncertainty}, \ie the ability of a cost function's minimum to correspond to the correct disparity. In this chapter, we will study how possibility distributions can be simply used on a cost volume to estimate its epistemic uncertainty. We design a method for traditional 3D reconstruction pipelines, with the final objective of reconstructing 3D models from satellite imagery. The uncertainty is represented by disparity confidence intervals, which complement classical confidence estimations as it provides information on \textit{where} the correct disparity should be. We then propagate disparity confidence intervals in the rest of the stereo pipeline to obtain height confidence intervals, and evaluate their performances.

\section{Cost functions as expert opinions}
In this chapter, we will consider two cost functions:
\begin{enumerate}
    \item CENSUS \cite{zabih_non-parametric_1994}, designed to be robust to radiometric variations preserving the relative orders on intensities
    \item MCCNN \cite{zbontar_stereo_2016}, learned-based similarity measure on a fixed $11\times 11$ window
\end{enumerate}
The CENSUS cost function is a common cost function for cost-volume-based methods, and is used in most 3D pipelines \cite{franchis_automatic_2014,shean_automated_2016,rupnik_micmac_2017,youssefi_cars_2020}. The MCCNN function has been shown to outperform CENSUS on benchmark datasets \cite{zbontar_stereo_2016} and present good generalization properties. Those functions are the two main methods used in the CARS pipeline, for which we will thus attempt to estimate the uncertainty. 

As stated previously, a cost function measures the similarity between patches of two images \(I_L,~I_R\). The similarity for every considered disparity and for every pixels of the left image are then stored in the cost volume, which is itself regularized using SGM algorithm or one of its variants. As such, the cost volume (and by extension all of its cost curves) contains both information on the similarity of patches, but also the global structure of the scene now that continuity constraints on the disparity map have been imposed. For instance, a low value of the cost volume at \( (row, col, d) \) usually indicates that the patches \(I_L(row,col)\)  and \(I_R(row,col+d)\) are somehow similar, and that neighbouring patches with close disparities are also similar. However, those two notions are mixed inside a cost value, so it is hard to differentiate between the similarity and the regularization part. The uncertainty linked to the cost volume is of epistemic nature, due to the regularization (and to the learned nature of the cost function in the case of MCCNN). We thus suggest to consider a cost function similarly as an expert providing insights on how \textit{possible} a match is, opinion for which the uncertainty can be modeled using possibility distributions for instance. We presented possibility distribution in section \ref{sec:possibilities}, which have been used to model the uncertainty of experts opinions in the applications such as groundwater contamination \cite{bardossy_l-_1995, baudrit_joint_2007}. Utilizing possibility distributions leverages the advanced capabilities of imprecise probability (IP) theory for epistemic uncertainty estimation.

Possibility distributions are effective for modeling expert opinions on the uncertainty of imprecise observations, as seen in applications like groundwater contamination \cite{bardossy_l-_1995, baudrit_joint_2007}. In stereo matching, a regularized cost curve obtained using SGM can be likened to an expert's assessment of whether two patches are homologous, based on their features and the overall properties of the cost volume. Utilizing possibility distributions leverages the advanced capabilities of imprecise probability (IP) theory for robust uncertainty estimation.

Stereo matching algorithms attempt to determine the disparity for every pixel of the left image. To do so, we look at the minimal disparity of every cost function separately, instead of considering the whole cost volume. We use the same approach and propose to generate a possibility distribution for each cost curve. To compute those possibility distributions, we first normalize the cost curve into a range of \([0,1]\), using the minimum and maximum values of the global cost volume after regularization. For a pixel \( p = (i, j) \), the normalized cost curve is given by:
\begin{equation}
    f_{i,j}^{norm}(d) = \frac{C_V(i,j,d) - \max C_V}{\min C_V - \max C_V} \label{eq:norm_cost_func}
\end{equation}
Here, the \(\min\) and \(\max\) operations are reversed to ensure higher possibility for lower values of the cost function. To ensure that there always exists a disparity for which the possibility is $1$ (equation \ref{eq:possibility}), \( f_{i,j}^{norm} \) is transformed into a possibility distribution \( \pi_{i,j}(d) \) by adding a constant:
\begin{equation}
    \pi_{i,j}(d) = f_{i,j}^{norm}(d) + 1 - \max_{d \in \mathcal{D}} f_{i,j}^{norm}(d) \label{eq:constant_norm}
\end{equation}
where \(\mathcal{D}\) refers to the disparity range considered. Note that the constants used in \ref{eq:norm_cost_func} are global for all possibility distributions, whereas the constant in equation \ref{eq:constant_norm} can vary between different possibility distributions. Constants from equations \ref{eq:norm_cost_func} determine which cost values are said to be the most possible match and impossible matches. Consequently, in order for the constants to be well defined and for the possibility distributions to have similar interpretations between different cost volume, the disparity range and images need to be large enough to ensure that the cost volume contains values for very similar and very dissimilar patches. This hypothesis is usually not very restrictive for the images used in stereo matching problem (except if the whole scene is covered by cloud for instance, which can be detected in advance).

\todoroman{Figure montrant différentes courbes de coût transformées, CENSUS MCCNN}
\section{Computing disparity intervals}
Simple seuil mais avec une base théorique

Ambiguity et régularization dans les zones de faibles confiance etc
\section{Propagation in the rest of the CARS pipeline}
Rasterization and small ideas with Gabriela?
Impact of tiling : cost volume min and max is not the same from one tile to another (statistically it should be close, provided that the tile is big enough and the disparity interval is also large enough)
\section{Coregistration}
\pagebreak